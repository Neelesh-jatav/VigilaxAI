# ğŸš VigilaxAI

AI-powered **Drone Detection & Surveillance System** with live video monitoring, multi-camera control, visual threat detection, and audio-based drone sound analysis.

---

## âœ¨ Overview

VigilaxAI combines computer vision + audio intelligence in a Flask-based web dashboard designed for real-time situational awareness.

It supports:
- ğŸ“¹ Live camera streaming (single/multi-camera environments)
- ğŸ¯ Visual drone detection
- ğŸ™ï¸ Audio drone signature detection (TensorFlow model)
- ğŸ§‘ Face detection
- ğŸ”ªğŸ”« Weapon detection (knife/gun)
- ğŸ’¾ Snapshot capture and video recording
- ğŸ—‚ï¸ Archive browsing for saved media and audio detections

---

## ğŸ§± Project Structure

```text
VigilaxAI/
â”œâ”€â”€ camera_feed_app/           # Main Flask surveillance app
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ routes/            # API + page routes
â”‚   â”‚   â”œâ”€â”€ services/          # Camera + AI detection services
â”‚   â”‚   â”œâ”€â”€ templates/         # HTML UI
â”‚   â”‚   â””â”€â”€ static/            # CSS, captures, recordings
â”‚   â”œâ”€â”€ config.py              # Runtime/environment config
â”‚   â””â”€â”€ run.py                 # App entrypoint
â”œâ”€â”€ audio1/                    # Audio model training + backend assets
â””â”€â”€ requirements.txt           # Root dependency entrypoint
```

---

## ğŸš€ Quick Start

### 1) Clone the repository

```bash
git clone https://github.com/Neelesh-jatav/VigilaxAI.git
cd VigilaxAI
```

### 2) Create & activate a virtual environment

**Windows (PowerShell):**
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

**macOS / Linux:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3) Install dependencies

```bash
pip install -r requirements.txt
```

For full audio-model tooling/training extras:

```bash
pip install -r audio1/requirements.txt
```

### 4) Run the app

```bash
python camera_feed_app/run.py
```

Open in browser:

```text
http://localhost:5000
```

---

## ğŸ§ª Main API Endpoints

### Camera & Stream
- `GET /api/cameras` â€” list available cameras
- `POST /api/select_camera` â€” switch active camera
- `POST /api/start` / `POST /api/stop` â€” start/stop stream
- `GET /video_feed` â€” MJPEG live stream
- `GET /api/status` â€” current camera/service state

### Detection Controls
- `POST /api/toggle_face`
- `POST /api/toggle_drone`
- `POST /api/toggle_knife`
- `POST /api/toggle_gun`
- `GET /api/ai_status`

### Audio Drone Detection
- `GET /api/audio_drone/status`
- `POST /api/audio_drone/predict` (multipart file upload)
- `GET /api/audio_drone/detections`
- `DELETE /api/audio_drone/detections/<filename>`

### Media & Archives
- `POST /api/capture`
- `POST /api/record/start`
- `POST /api/record/stop`
- `GET /archives`

---

## âš™ï¸ Configuration

Core settings are managed in `camera_feed_app/config.py` using environment variables.

Common options:
- `FLASK_HOST`, `FLASK_PORT`, `FLASK_DEBUG`
- `CAMERA_SCAN_MAX_INDEX`, `CAMERA_FPS`, frame size settings
- `DRONE_*` and `ROBOFLOW_*` for visual drone detection
- `AUDIO_DRONE_*` for audio model path, threshold, and spectrogram settings
- `WEAPON_*` for knife/gun detection behavior

---

## ğŸ§  Tech Stack

- **Backend:** Flask, Python
- **Computer Vision:** OpenCV, Ultralytics YOLO, Roboflow API (optional)
- **Audio AI:** TensorFlow/Keras, librosa, NumPy
- **Frontend:** HTML, CSS, JavaScript
- **Deployment:** Gunicorn, Procfile-based hosting

---

## âœ… Useful Commands

Run selected tests/examples from repository root:

```bash
python test_detection_api.py
python verify_audio_implementation.py
python camera_feed_app/test_live_detection.py
```

---

## ğŸ¤ Contributing

Contributions, bug reports, and feature requests are welcome.

1. Fork the repo
2. Create a feature branch
3. Commit your changes
4. Open a pull request

---

## ğŸ“Œ Notes

- Some advanced detection features require model files and/or external API keys.
- For audio upload support beyond WAV in some systems, installing `ffmpeg` can improve compatibility.

---

## ğŸ“„ License

Add your preferred license in this repository (for example: MIT) if not already set.

---

### Built for smarter perimeter awareness ğŸ‘ï¸â€ğŸ—¨ï¸
